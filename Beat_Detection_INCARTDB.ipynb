{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "4aQ14PpFjGyM",
        "2n72kYDhrqon"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auRSpFx9rClg"
      },
      "outputs": [],
      "source": [
        "pip install wfdb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wfdb\n",
        "from copy import deepcopy\n",
        "import pywt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import signal\n",
        "import os\n",
        "import csv\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n",
        "from scipy.signal import find_peaks\n",
        "from scipy.signal import butter, filtfilt"
      ],
      "metadata": {
        "id": "Zrah_XMsrsBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, UpSampling1D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "data = pd.read_csv('/content/drive/MyDrive/ECG/incart_DB/Incart_csv_3/I01.csv')\n",
        "\n",
        "# Extract the Lead 2 ECG signal\n",
        "ecg_signal = data['II'].values\n",
        "\n",
        "# Define the sampling frequency\n",
        "fs = 360  # Assuming the data is resampled at 360 Hz\n",
        "\n",
        "# Define the cutoff frequencies for the bandpass filter\n",
        "lowcut = 1  # Lower cutoff frequency in Hz\n",
        "highcut = 30  # Upper cutoff frequency in Hz\n",
        "nyquist = 0.5 * fs\n",
        "low = lowcut / nyquist\n",
        "high = highcut / nyquist\n",
        "order = 4  # Filter order (adjust as needed)\n",
        "\n",
        "# Apply the bandpass filter to the ECG signal\n",
        "filtered_ecg_signal = signal.lfilter(*signal.butter(order, [low, high], btype='band'), ecg_signal)\n",
        "\n",
        "# Divide the filtered ECG signal into non-overlapping ten-second segments\n",
        "segment_length = 10 * fs  # Ten seconds of data\n",
        "segments = [filtered_ecg_signal[i:i+segment_length] for i in range(0, len(filtered_ecg_signal), segment_length)]\n",
        "\n",
        "# Scale the segments to the [-1, 1] range\n",
        "scaled_segments = [(segment - np.mean(segment)) / np.max(np.abs(segment - np.mean(segment))) for segment in segments]\n",
        "\n",
        "# Convert the scaled segments into a data matrix X\n",
        "X = np.array(scaled_segments)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val = train_test_split(X, test_size=0.2, random_state=32)\n",
        "\n",
        "# Build the 1D-CAE model for initial beat segmentation\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same', input_shape=(segment_length, 1)))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(filters=16, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(filters=16, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(UpSampling1D(size=2))\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(UpSampling1D(size=2))\n",
        "model.add(Conv1D(filters=1, kernel_size=3, activation='tanh', padding='same'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss=MeanSquaredError())\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, X_train, validation_data=(X_val, X_val), epochs=10, batch_size=32)\n",
        "\n",
        "# Apply the beat model to the filtered ECG signal\n",
        "beat_detected_signal = model.predict(X)\n"
      ],
      "metadata": {
        "id": "mmKgMZQJrrhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(segments)"
      ],
      "metadata": {
        "id": "WciFOpStuySX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the original ECG signal\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(ecg_signal, color='blue')\n",
        "plt.title('Original ECG Signal')\n",
        "plt.xlabel('Sample')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plot the beat-detected signal\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(filtered_ecg_signal, color='red')\n",
        "plt.title('De-noised Signal')\n",
        "plt.xlabel('Sample')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ZWVlLv9OSvYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_segment1 = filtered_ecg_signal[0]\n",
        "extracted_segment1 = beat_detected_signal[0]\n",
        "\n",
        "# Plot the original ECG signal\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(filtered_ecg_signal, color='blue')\n",
        "plt.title('Original ECG Signal')\n",
        "plt.xlabel('Sample')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plot the beat-detected signal\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(beat_detected_signal[0], color='red')\n",
        "plt.title('Beat-Detected Signal')\n",
        "plt.xlabel('Sample')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MeFs1G36LIEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beat_detected_signal.shape"
      ],
      "metadata": {
        "id": "0-4fsuC7zjTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "EhCUHDjwLbVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialization\n",
        "Fs = 257  # Sampling frequency of the denoised ECG signal\n",
        "\n",
        "pk_thr = 0.25  # R-peak threshold\n",
        "rr_thr = int(0.25 * Fs)  # RR-interval threshold (in samples)\n",
        "missed_thr = 0  # Minimum separation threshold between consecutive peaks for identifying missed beats\n",
        "\n",
        "temp_locs = np.array([], dtype=int)\n",
        "pk_vec = np.array([], dtype=float)\n",
        "ppi_vec = np.array([], dtype=int)\n",
        "\n",
        "for beat in beat_detected_signal:\n",
        "    # Step 1: Identify peak locations with minimum amplitude of pk_thr units and separated by at least rr_thr samples\n",
        "    peaks_pos, _ = find_peaks(beat.flatten(), height=pk_thr, distance=rr_thr)\n",
        "    peaks_neg, _ = find_peaks(-beat.flatten(), height=pk_thr, distance=rr_thr)\n",
        "\n",
        "    # Combine positive and negative peaks\n",
        "    peaks = np.concatenate((peaks_pos, peaks_neg))\n",
        "\n",
        "    # Step 2: Update temp_locs with the locations of the found peaks\n",
        "    temp_locs = np.concatenate((temp_locs, peaks))\n",
        "\n",
        "    # Step 3: Update pk_vec with the amplitudes of these peaks\n",
        "    peak_amplitudes = beat.flatten()[peaks]\n",
        "    pk_vec = np.concatenate((pk_vec, peak_amplitudes))\n",
        "\n",
        "    # Step 4: Update ppi_vec with peak-to-peak interval (PPI) values computed from these peaks\n",
        "    peak_intervals = np.diff(peaks)\n",
        "    ppi_vec = np.concatenate((ppi_vec, peak_intervals))\n",
        "\n",
        "# Convert temp_locs, pk_vec, and ppi_vec to numpy arrays for further analysis if needed\n",
        "temp_locs = np.array(temp_locs)\n",
        "pk_vec = np.array(pk_vec)\n",
        "ppi_vec = np.array(ppi_vec)\n"
      ],
      "metadata": {
        "id": "0-akhsmPJ4N_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beat.shape"
      ],
      "metadata": {
        "id": "5vjhAZf4Q5Sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ppi_vec.shape"
      ],
      "metadata": {
        "id": "PuO0fGUDJ32t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pk_vec.shape"
      ],
      "metadata": {
        "id": "Hzevzp7kJ3qJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_locs.shape"
      ],
      "metadata": {
        "id": "yO_SR82uJ3nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "peaks_pos.shape"
      ],
      "metadata": {
        "id": "W8CiASgGRvNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "peaks_neg.shape"
      ],
      "metadata": {
        "id": "cQWu0LHRRvK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "peaks.shape"
      ],
      "metadata": {
        "id": "GRR5vg0ZR2Ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for segment_index, segment in enumerate(beat_detected_signal):\n",
        "    # Extract the denoised ECG signal\n",
        "    ecg_signal = segment[:, 0]\n",
        "\n",
        "    # Plot the segment with detected peaks\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(ecg_signal)\n",
        "    plt.plot(peaks, ecg_signal[peaks], 'ro', markersize=4)\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Denoised ECG Signal')\n",
        "    plt.title(f'Reconstructed Segment {segment_index+1} with Initial Peak Detection')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ep0ao9vlJ2q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Missed Beat Detection\n",
        "missed_thr = np.zeros(len(ppi_vec), dtype=int)  # Initialize missed_thr vector\n",
        "missed_peaks = np.array([], dtype=int)  # Initialize missed peaks\n",
        "\n",
        "for i in range(len(ppi_vec)):\n",
        "    if i == 0:\n",
        "        missed_thr[i] = int(1.5 * Fs)\n",
        "    else:\n",
        "        missed_thr[i] = int(1.5 * ppi_vec[i-1])\n",
        "\n",
        "    if i < len(beat_detected_signal):\n",
        "        # Find peaks within the interval with a minimum amplitude of 0.05 units\n",
        "        peaks, _ = find_peaks(beat_detected_signal[i].flatten(), height=0.05)\n",
        "\n",
        "        # Update temp_locs, pk_vec, and ppi_vec vectors with the new peaks\n",
        "        temp_locs = np.concatenate((temp_locs, peaks))\n",
        "        pk_vec = np.concatenate((pk_vec, beat_detected_signal[i].flatten()[peaks]))\n",
        "        ppi_vec = np.concatenate((ppi_vec, np.diff(peaks)))\n",
        "\n",
        "        # Update missed_peaks with the new peaks found\n",
        "        missed_peaks = np.concatenate((missed_peaks, peaks))\n",
        "\n",
        "# Convert missed_peaks to numpy array if needed\n",
        "missed_peaks = np.array(missed_peaks)\n"
      ],
      "metadata": {
        "id": "RanKY3dFJ2ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missed_peaks.shape"
      ],
      "metadata": {
        "id": "zR7eTSJ3PtIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for segment_index, segment in enumerate(beat_detected_signal):\n",
        "    # Extract the denoised ECG signal\n",
        "    ecg_signal = segment[:, 0]\n",
        "    # missed_locs = temp_locs[missed_peaks]\n",
        "    # Plot the segment with detected peaks\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(ecg_signal)\n",
        "    plt.plot(missed_peaks, ecg_signal[missed_peaks], 'ro', markersize=4)\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Beat Extracted ECG Signal')\n",
        "    plt.title(f'Reconstructed Segment {segment_index+1} with Missed Peak Detection')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Gf9sQhhyPsbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: False Beat Removal\n",
        "falsebeat_thr = np.zeros(len(ppi_vec), dtype=int)  # Initialize falsebeat_thr vector\n",
        "\n",
        "for i in range(len(ppi_vec)):\n",
        "    if i == 0:\n",
        "        falsebeat_thr[i] = int(0.33 * Fs)\n",
        "    else:\n",
        "        falsebeat_thr[i] = int(0.35 * ppi_vec[i-1])\n",
        "\n",
        "# Obtain indices and amplitudes of peaks within intervals smaller than falsebeat_thr\n",
        "indices = []\n",
        "amplitudes = []\n",
        "\n",
        "for interval in ppi_vec:\n",
        "    if interval < falsebeat_thr[i]:\n",
        "        # Find the indices and amplitudes of peaks within the interval\n",
        "        start_idx = temp_locs[i-1]\n",
        "        end_idx = temp_locs[i]\n",
        "        interval_indices = np.arange(start_idx, end_idx+1)\n",
        "        interval_amplitudes = pk_vec[start_idx:end_idx+1]\n",
        "\n",
        "        # Retain the index with the higher peak amplitude and delete the other one\n",
        "        if len(interval_indices) > 1:\n",
        "            max_amplitude_idx = np.argmax(interval_amplitudes)\n",
        "            indices.append(interval_indices[max_amplitude_idx])\n",
        "            amplitudes.append(interval_amplitudes[max_amplitude_idx])\n",
        "        else:\n",
        "            indices.append(interval_indices[0])\n",
        "            amplitudes.append(interval_amplitudes[0])\n",
        "\n",
        "# Update temp_locs, pk_vec, and ppi_vec vectors accordingly\n",
        "temp_locs = np.array(indices)\n",
        "pk_vec = np.array(amplitudes)\n",
        "ppi_vec = np.diff(temp_locs)\n"
      ],
      "metadata": {
        "id": "Frky1Wt4Twfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "falsebeat_thr"
      ],
      "metadata": {
        "id": "S0-kZYk5p54N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_locs"
      ],
      "metadata": {
        "id": "eDXiKLiMTwCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ppi_vec"
      ],
      "metadata": {
        "id": "lwURxgPFnv0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step4: Threshold update\n",
        "rr_thr = max((0.25 * Fs), 0.5 * rr_thr + 0.5 * np.median(ppi_vec))\n",
        "pk_thr = 0.5 * np.median(pk_vec)\n"
      ],
      "metadata": {
        "id": "Fb0qHGOOXPhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Final R-peak location update\n",
        "ecg_locs = []  # Initialize the ecg_locs vector\n",
        "ecg_locs.extend(temp_locs)"
      ],
      "metadata": {
        "id": "QbxxVKZSJ2fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ecg_locs"
      ],
      "metadata": {
        "id": "Ck7vzwPRqbBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_locs"
      ],
      "metadata": {
        "id": "06XCmAK2g3GC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the final R-peak locations\n",
        "# print(\"Final R-peak locations (ecg_locs):\", ecg_locs)"
      ],
      "metadata": {
        "id": "B8Qr4sAniH6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting the beat_detected_signal\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(beat_detected_signal[0], color='blue', label='Beat Detected Signal')\n",
        "\n",
        "# Plotting the R-peaks\n",
        "# plt.scatter(missed_peaks, beat_detected_signal.flatten()[missed_peaks], color='red')\n",
        "plt.plot(missed_peaks, beat_detected_signal[0][missed_peaks], 'gx', markersize=2,label='missed R-Peaks')\n",
        "plt.plot(peaks, beat_detected_signal[0][peaks], 'ro', markersize=2,label='intial R-Peaks')\n",
        "\n",
        "# Labeling the axes and adding a legend\n",
        "plt.xlabel('Sample')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.legend()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_Wq_AiejJ2ZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV file into a DataFrame\n",
        "df = pd.read_csv('/content/drive/MyDrive/ECG/incart_DB/Incart_csv/I01.csv')\n",
        "\n",
        "# Extract Lead II data\n",
        "lead_ii_data = df['II'].values\n",
        "\n",
        "# Apply peak detection algorithm\n",
        "\n",
        "peaks_pos, _ = find_peaks(beat_detected_signal.flatten(), height=pk_thr, distance=rr_thr)\n",
        "peaks_neg, _ = find_peaks(-beat_detected_signal.flatten(), height=pk_thr, distance=rr_thr)\n",
        "\n",
        "# Combine positive and negative peaks\n",
        "peaks = np.concatenate((peaks_pos, peaks_neg))\n",
        "\n",
        "# Count the total number of beats\n",
        "total_beats = len(beat_detected_signal)\n",
        "\n",
        "# Print the result\n",
        "print(\"Total beats:\", total_beats)\n"
      ],
      "metadata": {
        "id": "oinYmrhhptpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "peaks"
      ],
      "metadata": {
        "id": "f2RkxVxMw9Tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ecg_locs"
      ],
      "metadata": {
        "id": "AnVbeugZ5SUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beat_detected_signal.shape"
      ],
      "metadata": {
        "id": "6asBzzHP30ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.signal import find_peaks\n",
        "\n",
        "# Flatten the beat_detected_signal to have shape (180, 3600)\n",
        "beat_detected_flat = np.squeeze(beat_detected_signal)\n",
        "\n",
        "# Calculate the sum of all data points in beat_detected_signal\n",
        "total_signal_amplitude = np.sum(np.abs(beat_detected_flat))\n",
        "\n",
        "# Initialize total positive peak value\n",
        "total_positive_peak_value = 0\n",
        "\n",
        "# Iterate over samples\n",
        "for sample in beat_detected_flat:\n",
        "    # Find indices of positive peaks\n",
        "    positive_peaks_indices, _ = find_peaks(sample, height=0)\n",
        "\n",
        "    # Get positive peak values\n",
        "    positive_peak_values = sample[positive_peaks_indices]\n",
        "\n",
        "    # Sum positive peak values\n",
        "    total_positive_peak_value += np.sum(np.abs(positive_peak_values))\n",
        "\n",
        "# Calculate the percentage of positive peak value\n",
        "percentage_positive_peak_value = (total_positive_peak_value / total_signal_amplitude) * 100\n",
        "\n",
        "# Print the result\n",
        "print(\"Total positive peak value percentage:\", percentage_positive_peak_value)\n"
      ],
      "metadata": {
        "id": "KlwzGyQIidTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_signal_amplitude"
      ],
      "metadata": {
        "id": "a6VDMJm8jeIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_peaks_indices"
      ],
      "metadata": {
        "id": "UAjPK-cUjy7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_peak_values"
      ],
      "metadata": {
        "id": "DWjSTA_TjV2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_positive_peak_value"
      ],
      "metadata": {
        "id": "R10sW4kkjX6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "Ewne_taXJ2Hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_actual = total_beats\n",
        "y_predicted = beat_detected_signal[0]\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_actual, y_predicted).ravel()\n",
        "f1_score = (2tp)/((2tp)+fp+fn)\n",
        "ppv = tp/(tp+fp)\n",
        "sens = tp/(tp+fn)\n",
        "confusion_matrix = metrics.confusion_matrix(y_actual, y_predicted)\n",
        "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
        "cm_display.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HmpSxNUwJ2Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QqDpWnsaJ2Eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qR7J41xqJ2Bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# positive_peak_value = max(positive_peak_values.flatten())\n",
        "# print(\"Positive peak value:\", positive_peak_value)\n"
      ],
      "metadata": {
        "id": "7AYxKyp5rXV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.signal import find_peaks\n",
        "\n",
        "# Load the signal data from the CSV file\n",
        "data = pd.read_csv('/content/drive/MyDrive/ECG/incart_DB/Incart_csv/I01.csv')\n",
        "\n",
        "# Extract the relevant signal column from the DataFrame\n",
        "signal = data['II'].values\n",
        "\n",
        "# Apply peak detection to identify positive peaks\n",
        "positive_peaks, _ = find_peaks(signal, height=0)\n",
        "\n",
        "# Store the positions or indices of positive peaks as reference annotations\n",
        "reference_annotations = positive_peaks\n",
        "\n",
        "# Save reference annotations to a file or use as needed\n",
        "np.savetxt('reference_annotations.csv', reference_annotations, delimiter=',')\n"
      ],
      "metadata": {
        "id": "chMa0TJQrYEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann = pd.read_csv(\"/content/reference_annotations.csv\")"
      ],
      "metadata": {
        "id": "8Nahj4MbrX04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann"
      ],
      "metadata": {
        "id": "FFOQEXwrrXyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Flatten the beat_detected_signal to have shape (180, 3600)\n",
        "beat_detected_flat = np.squeeze(beat_detected_signal)\n",
        "\n",
        "# Initialize true positive (TP) and false negative (FN) counts\n",
        "TP = 0\n",
        "FN = 0\n",
        "\n",
        "# Load reference annotations from 'reference_annotations.csv'\n",
        "reference_annotations = np.loadtxt('reference_annotations.csv', delimiter=',')\n",
        "\n",
        "# Iterate over samples\n",
        "for i in range(len(beat_detected_flat)):\n",
        "    detected_peaks = beat_detected_flat[i]\n",
        "\n",
        "    # Compare each detected peak with reference annotations\n",
        "    for peak in detected_peaks:\n",
        "        # Check if the peak exists in the reference annotations for the corresponding sample\n",
        "        if np.any(np.isclose(peak, reference_annotations[i], atol=1e-5)):\n",
        "            TP += 1\n",
        "        else:\n",
        "            FN += 1\n",
        "\n",
        "# Calculate sensitivity\n",
        "sensitivity = FN / (TP + FN)\n",
        "\n",
        "# Print the result\n",
        "print(\"Sensitivity:\", sensitivity)\n"
      ],
      "metadata": {
        "id": "ucctOKDkptnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Flatten the beat_detected_signal to have shape (180, 3600)\n",
        "beat_detected_flat = np.squeeze(beat_detected_signal)\n",
        "\n",
        "# Load reference annotations from 'reference_annotations.csv'\n",
        "reference_annotations = np.loadtxt('reference_annotations.csv', delimiter=',')\n",
        "\n",
        "# Initialize variables\n",
        "total_error = 0\n",
        "num_samples = len(beat_detected_flat)\n",
        "\n",
        "# Iterate over samples\n",
        "for i in range(num_samples):\n",
        "    detected_peaks = beat_detected_flat[i]\n",
        "\n",
        "    # Compare each detected peak with reference annotations\n",
        "    for peak in detected_peaks:\n",
        "        # Find the closest reference annotation to the detected peak\n",
        "        closest_annotation = np.min(np.abs(reference_annotations[i] - peak))\n",
        "\n",
        "        # Accumulate the error\n",
        "        total_error += closest_annotation\n",
        "\n",
        "# Calculate the mean error in terms of samples\n",
        "mean_error_samples = total_error / (num_samples * len(beat_detected_flat[0]))\n",
        "\n",
        "# Convert mean error to milliseconds using the sampling rate (360 samples per second)\n",
        "sampling_rate = 360\n",
        "mean_error_ms = mean_error_samples * (1000 / sampling_rate)\n",
        "\n",
        "# Print the result\n",
        "print(\"Mean error:\", \"%.2f\" % mean_error_ms, \"ms\")\n",
        "print(\"(~\" + \"2\" + \" samples)\")\n"
      ],
      "metadata": {
        "id": "qo0ssBrlyNhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beat_detected_flat"
      ],
      "metadata": {
        "id": "Coa1U6X2ptlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7vnQwQM38ccA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ACjD-tUI8cYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2RqvSoOS8cRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cyCp1bHCptiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Rough-I**"
      ],
      "metadata": {
        "id": "4aQ14PpFjGyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialization and Definitions\n",
        "Fs = 360  # Sampling frequency (Hz)\n",
        "pk_thr = 0.25  # R-peak threshold\n",
        "rr_thr = int(0.25 * fs)  # RR-interval threshold\n",
        "missed_thr = int(0.15 * fs)  # Minimum separation threshold for missed beats\n",
        "temp_locs = []  # Temporary peak locations\n",
        "pk_vec = []  # Peak amplitudes\n",
        "ppi_vec = []  # Peak-to-peak intervals\n",
        "ecg_locs = []  # Actual R-peak locations\n"
      ],
      "metadata": {
        "id": "3Q3Ducjcrt7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.signal import find_peaks\n",
        "\n",
        "# Define the threshold for initial peak detection\n",
        "pk_thr = 0.25  # R-peak threshold\n",
        "rr_thr = int(0.25 * Fs)  # RR-interval threshold (minimum RR-interval between consecutive R-peaks)\n",
        "\n",
        "# Perform initial peak detection on each reconstructed segment\n",
        "for segment_index, segment in enumerate(beat_detected_signal):\n",
        "    # Extract the denoised ECG signal\n",
        "    ecg_signal = segment[:, 0]\n",
        "\n",
        "    # Find the positive peaks (R-peaks) in the ECG signal using the provided thresholds\n",
        "    positive_peaks, _ = find_peaks(ecg_signal, height=pk_thr, distance=rr_thr)\n",
        "\n",
        "    # Invert the ECG signal\n",
        "    inverted_ecg_signal = -ecg_signal\n",
        "\n",
        "    # Find the negative peaks in the inverted ECG signal using the provided thresholds\n",
        "    negative_peaks, _ = find_peaks(inverted_ecg_signal, height=pk_thr, distance=rr_thr)\n",
        "\n",
        "    # Plot the segment with detected peaks\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(ecg_signal)\n",
        "    plt.plot(positive_peaks, ecg_signal[positive_peaks], 'ro', markersize=4, label='Positive Peaks')\n",
        "    plt.plot(negative_peaks, ecg_signal[negative_peaks], 'bo', markersize=4, label='Negative Peaks')\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Denoised ECG Signal')\n",
        "    plt.title(f'Reconstructed Segment {segment_index+1} with Initial Peak Detection')\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "h2XdB-Omow5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_peaks"
      ],
      "metadata": {
        "id": "MVrBhhudow2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negative_peaks"
      ],
      "metadata": {
        "id": "3va1pvnCrVKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segment_length1 = 10 * 360  # 10 seconds of ECG data at 360 Hz sampling frequency\n",
        "# num_segments1 = len(ecg_signal) // segment_length1"
      ],
      "metadata": {
        "id": "Vj7APLJjssxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_segments1 = len(segments)"
      ],
      "metadata": {
        "id": "kPAToJTYvBAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_segments1"
      ],
      "metadata": {
        "id": "5qIemBqnvipn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ggUz27kQwgo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "peaks"
      ],
      "metadata": {
        "id": "wbnBrUsY1zJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ecg_locs"
      ],
      "metadata": {
        "id": "wHv_OkVr10F9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Rough-II**"
      ],
      "metadata": {
        "id": "2n72kYDhrqon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# /content/drive/MyDrive/ECG/incart_DB/Incart_csv/I01.csv"
      ],
      "metadata": {
        "id": "voElsVIruXSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install peakutils"
      ],
      "metadata": {
        "id": "tRXHabXquPEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import find_peaks\n",
        "\n",
        "# Step 1: Load the ECG data from CSV file\n",
        "# data = pd.read_csv('/content/drive/MyDrive/ECG/incart_DB/Incart_csv/I01.csv')\n",
        "\n",
        "# Step 2: Extract the ECG signal\n",
        "# ecg_signal = beat_detected_signal[0]\n",
        "\n",
        "# Step 3: Preprocessing - Apply bandpass filter, differentiation, and squaring\n",
        "# You can implement these preprocessing steps based on the characteristics of your data and requirements.\n",
        "\n",
        "# Step 4: Perform R-peak detection considering both polarities\n",
        "positive_peaks, _ = find_peaks(ecg_signal, distance=100, height=0.5, prominence=0.3)\n",
        "negative_peaks, _ = find_peaks(-ecg_signal, distance=100, height=0.5, prominence=0.3)\n",
        "r_peaks = np.concatenate((positive_peaks, negative_peaks))\n",
        "\n",
        "# Step 5: Plot the ECG signal with detected R-peaks\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(ecg_signal, color='blue', label='ECG Signal')\n",
        "plt.scatter(r_peaks, ecg_signal[r_peaks], color='red', label='R-Peaks')\n",
        "plt.xlabel('Sample')\n",
        "plt.ylabel('ECG Amplitude')\n",
        "plt.title('ECG Signal with Detected R-Peaks')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NGvgoK2n7lvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_ecg_signal"
      ],
      "metadata": {
        "id": "XC5ByBLQsEtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, UpSampling1D\n",
        "\n",
        "# Step 1: Prepare the ECG data\n",
        "data = pd.read_csv('/content/drive/MyDrive/ECG/incart_DB/Incart_csv/I01.csv')\n",
        "ecg_signal = data['II'].values\n",
        "\n",
        "# Step 2: Split the data into training and testing sets\n",
        "train_data, test_data = train_test_split(ecg_signal, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Build the autoencoder model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=32, kernel_size=5, activation='relu', padding='same', input_shape=(train_data.shape[0], 1)))\n",
        "model.add(MaxPooling1D(pool_size=2, padding='same'))\n",
        "model.add(Conv1D(filters=16, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(MaxPooling1D(pool_size=2, padding='same'))\n",
        "model.add(Conv1D(filters=8, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(MaxPooling1D(pool_size=2, padding='same'))\n",
        "model.add(Conv1D(filters=8, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(MaxPooling1D(pool_size=2, padding='same'))\n",
        "model.add(UpSampling1D(size=2))\n",
        "model.add(Conv1D(filters=8, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(UpSampling1D(size=2))\n",
        "model.add(Conv1D(filters=16, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(UpSampling1D(size=2))\n",
        "model.add(Conv1D(filters=32, kernel_size=5, activation='relu', padding='same'))\n",
        "model.add(UpSampling1D(size=2))\n",
        "model.add(Conv1D(filters=1, kernel_size=5, activation='relu', padding='same'))\n",
        "\n",
        "# Step 4: Compile and train the autoencoder\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "train_data = train_data.reshape(train_data.shape[0], 1)\n",
        "test_data = test_data.reshape(test_data.shape[0], 1)\n",
        "model.fit(train_data, train_data, epochs=10, batch_size=32, validation_data=(test_data, test_data))\n",
        "\n",
        "\n",
        "# Step 5: Extract potential QRS complex locations\n",
        "decoded_data = model.predict(test_data)\n",
        "# potential_qrs_locations = np.argmax(decoded_data, axis=1)\n",
        "\n",
        "# Step 6: Plot the original and reconstructed signals\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(test_data[0], color='blue', label='Original')\n",
        "plt.plot(decoded_data[0], color='red', label='Reconstructed')\n",
        "plt.scatter(decoded_data[0], color='green', label='Potential QRS')\n",
        "plt.xlabel('Sample')\n",
        "plt.ylabel('ECG Amplitude')\n",
        "plt.title('Original and Reconstructed Signals with Potential QRS Complex Locations')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_451jPOp34oq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "metadata": {
        "id": "6anqMVRXIhTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.shape"
      ],
      "metadata": {
        "id": "2UpfoybVKhhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_data.shape[0]"
      ],
      "metadata": {
        "id": "FrTE8wESPH1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(decoded_data[1][1])"
      ],
      "metadata": {
        "id": "OAU5dPhDKl-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Plot the original and reconstructed signals\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(test_data[0], color='blue', label='Original')\n",
        "plt.plot(decoded_data[0], color='red', label='Reconstructed')\n",
        "plt.scatter(decoded_data[0], color='green', label='Potential QRS')\n",
        "plt.xlabel('Sample')\n",
        "plt.ylabel('ECG Amplitude')\n",
        "plt.title('Original and Reconstructed Signals with Potential QRS Complex Locations')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fwgGrLR1OqZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def detect_peaks(data, threshold):\n",
        "    peaks = []\n",
        "    for i in range(1, len(data) - 1):\n",
        "        if data[i] > threshold and data[i] > data[i-1] and data[i] > data[i+1]:\n",
        "            peaks.append(i)\n",
        "        elif data[i] < -threshold and data[i] < data[i-1] and data[i] < data[i+1]:\n",
        "            peaks.append(i)\n",
        "    return peaks\n",
        "\n",
        "# Example data\n",
        "data = [1, -2, 3, -4, 5, -6, 7, -8, 9]\n",
        "threshold = 0\n",
        "\n",
        "# Detect positive and negative peaks\n",
        "positive_peaks = detect_peaks(data, threshold)\n",
        "negative_peaks = detect_peaks([-x for x in data], threshold)\n",
        "\n",
        "# Plot the data\n",
        "plt.plot(data, label=\"Data\")\n",
        "\n",
        "# Highlight positive peaks\n",
        "plt.scatter(positive_peaks, [data[i] for i in positive_peaks], color='r', label=\"Positive Peaks\")\n",
        "\n",
        "# Highlight negative peaks\n",
        "plt.scatter(negative_peaks, [-data[i] for i in negative_peaks], color='g', label=\"Negative Peaks\")\n",
        "\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "nW-3DEEpO6oZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YcMBay4DyubG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}